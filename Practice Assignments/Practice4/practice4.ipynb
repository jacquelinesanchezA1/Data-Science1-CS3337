{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2a307f",
   "metadata": {},
   "source": [
    "# Week 4 Lab (Linear Regression)\n",
    "COSC 3337 Dr. Rizk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c732ee5",
   "metadata": {},
   "source": [
    "## About The Data\n",
    "Our goal for this lab is construct a model that can take a certain set of housing features and give us back a price estimate. Since price is a continuous variable, linear regression may be a good place to start from.\n",
    "The dataset that we'll be using for this task comes from kaggle.com and contains the following attributes:\n",
    "* 'Avg. Area Income': Avg. income of residents of the city house is located in.\n",
    "* 'Avg. Area House Age': Avg age of houses in same city\n",
    "* 'Avg. Area Number of Rooms': Avg number of rooms for houses in same city\n",
    "* 'Avg. Area Number of Bedrooms': Avg number of bedrooms for houses in same city\n",
    "* 'Area Population': Population of city house is located in\n",
    "* 'Price': Price that the house sold at (target)\n",
    "* 'Address': Address for the house"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3d19c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Let's begin by importing some necessary libraries that we'll be using to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b70c7",
   "metadata": {},
   "source": [
    "Our first step is to load the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0db4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('USA_Housing.csv')\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6683c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268afca",
   "metadata": {},
   "source": [
    "A quick pairplot lets us get an idea of the distributions and relationships in our dataset. From here, we could choose any interesting features that we'd like to later explore in greater depth. Warning: The more features in our dataset, the harder our pairplot will be to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205d995",
   "metadata": {},
   "source": [
    "Taking a closer look at price, we see that it's normally distributed with a peak around 1.232073e+06, and 75% of houses sold were at a price of 1.471210e+06 or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(housing_data['Price'])\n",
    "plt.show()\n",
    "print(housing_data['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a342592",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Price', y='Avg. Area Income', data=housing_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Avg. Area Number of Bedrooms', data=housing_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(housing_data.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30c58c",
   "metadata": {},
   "source": [
    "## Creating Our Linear Model\n",
    "We're now ready to begin creating and training our model. We first need to split our data into training and testing sets. This can be done using sklearn's train_test_split(X, y, test_size) function. This function takes in your features (X), the target variable (y), and the test_size you'd like (Generally a test size of around 0.3 is good enough). It will then return a tuple of X_train, X_test, y_train, y_test sets for us. We will train our model on the training set and then use the test set to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a643b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing_data[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population']]\n",
    "y = housing_data['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)\n",
    "plt.scatter(y_test,predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539850a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - predictions\n",
    "sns.histplot(residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f3928",
   "metadata": {},
   "source": [
    "Here are the most common evaluation metrics for regression problems:\n",
    "* **Mean Absolute Error (MAE)** is the mean of the absolute value of the errors:\n",
    "* **Mean Squared Error (MSE)** is the mean of the squared errors:\n",
    "* **Root Mean Squared Error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "Comparing these metrics:\n",
    "* MAE is the easiest to understand, because it's the average error.\n",
    "* MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "* RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are loss functions, because we want to minimize them.\n",
    "\n",
    "Luckily, sklearn can calculate all of these metrics for us. All we need to do is pass the true labels (y_test) and our predictions to the functions below. What's more important is that we understand what each of these means. Root Mean Square Error (RMSE) is what we'll most commonly use, which is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells us how concentrated the data is around the line of best fit. Determining a good RMSE depends on your data. You can find a great example here, or refer back to the power points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('R2 Score:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a458fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
